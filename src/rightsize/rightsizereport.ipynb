{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters",
     "report_exclude"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "report_exclude"
    ]
   },
   "outputs": [],
   "source": [
    "# Build the dataset\n",
    "\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import functools\n",
    "\n",
    "\n",
    "def add_parent_level(df: pd.DataFrame, name: str) -> None:\n",
    "    df.columns = pd.MultiIndex.from_tuples([(name, x) for x in df.columns])\n",
    "\n",
    "\n",
    "def calculate_limit(row: pd.Series, attribute: str) -> Optional[float]:\n",
    "    row_analysis = local_analysis.get(row.name)\n",
    "    if row_analysis is None:\n",
    "        return None\n",
    "    vm_spec = compute_specs.virtual_machine_by_name(row_analysis.advisor_sku)\n",
    "    return getattr(vm_spec.capabilities, attribute)\n",
    "\n",
    "\n",
    "def add_limit(df: pd.DataFrame, name: str) -> None:\n",
    "    df['new_limit'] = df.apply(functools.partial(calculate_limit, attribute=name), axis=1)\n",
    "\n",
    "drop_utilization = ['samples', 'percentile_50th', 'percentile_80th']\n",
    "drop_disk_utilization = ['cached', 'counter_name']\n",
    "\n",
    "res_data = resources.assign(resource_name=resources.resource_id.str.extract(r'([^/]+)$'))\n",
    "res_data = res_data.drop(columns=['subscription_id', 'storage_profile'])\n",
    "res_data = res_data.set_index('resource_id')\n",
    "res_data_col = res_data.columns.to_list()\n",
    "res_data_col = res_data_col[1:-1] + res_data_col[-1:] + res_data_col[0:1]\n",
    "res_data = res_data[res_data_col]\n",
    "add_parent_level(res_data, 'Resource')\n",
    "\n",
    "if local_analysis:\n",
    "    local_data = pd.DataFrame([(k, v.advisor_sku, v.advisor_sku_invalid_reason, v.annual_savings_no_ri) for k,v in local_analysis.items()], columns=['resource_id', 'recommendation', 'invalidation', 'annual_savings']).convert_dtypes()\n",
    "    local_data = local_data.set_index('resource_id')\n",
    "    add_parent_level(local_data, 'AzMeta')\n",
    "\n",
    "if advisor_analysis:\n",
    "    advisor_data = pd.DataFrame([(k, v.advisor_sku, v.advisor_sku_invalid_reason) for k,v in advisor_analysis.items()], dtype='string', columns=['resource_id', 'recommendation', 'invalidation'])\n",
    "    advisor_data = advisor_data.set_index('resource_id')\n",
    "    add_parent_level(advisor_data, 'Advisor')\n",
    "\n",
    "cpu_data = cpu_utilization.drop(columns=drop_utilization).set_index('resource_id')\n",
    "add_limit(cpu_data, 'd_total_acus')\n",
    "add_parent_level(cpu_data, 'CPU Used (ACUs)')\n",
    "\n",
    "mem_data = mem_utilization.drop(columns=drop_utilization).set_index('resource_id')\n",
    "mem_data = mem_data / 1024.0\n",
    "add_limit(mem_data, 'memory_gb')\n",
    "add_parent_level(mem_data, 'Memory Used (GiB)')\n",
    "\n",
    "disk_tput_cached = disk_utilization[(disk_utilization.cached == True) & (disk_utilization.counter_name == 'Disk Bytes/sec')]\n",
    "disk_tput_cached = disk_tput_cached.drop(columns=drop_utilization + drop_disk_utilization).set_index('resource_id')\n",
    "add_limit(disk_tput_cached, 'combined_temp_disk_and_cached_read_bytes_per_second')\n",
    "disk_tput_cached = disk_tput_cached / (1024.0 ** 2)\n",
    "add_parent_level(disk_tput_cached, 'Cached Disk Througput (MiB/sec)')\n",
    "\n",
    "disk_trans_cached = disk_utilization[(disk_utilization.cached == True) & (disk_utilization.counter_name == 'Disk Transfers/sec')]\n",
    "disk_trans_cached = disk_trans_cached.drop(columns=drop_utilization + drop_disk_utilization).set_index('resource_id')\n",
    "add_limit(disk_trans_cached, 'combined_temp_disk_and_cached_iops')\n",
    "add_parent_level(disk_trans_cached, 'Cached Disk Operations (IOPS)')\n",
    "\n",
    "disk_tput_uncached = disk_utilization[(disk_utilization.cached == False) & (disk_utilization.counter_name == 'Disk Bytes/sec')]\n",
    "disk_tput_uncached = disk_tput_uncached.drop(columns=drop_utilization + drop_disk_utilization).set_index('resource_id')\n",
    "add_limit(disk_tput_uncached, 'uncached_disk_bytes_per_second')\n",
    "disk_tput_uncached = disk_tput_uncached / (1024.0 ** 2)\n",
    "add_parent_level(disk_tput_uncached, 'Uncached Disk Througput (MiB/sec)')\n",
    "\n",
    "disk_trans_uncached = disk_utilization[(disk_utilization.cached == False) & (disk_utilization.counter_name == 'Disk Transfers/sec')]\n",
    "disk_trans_uncached = disk_trans_uncached.drop(columns=drop_utilization + drop_disk_utilization).set_index('resource_id')\n",
    "add_limit(disk_trans_uncached, 'uncached_disk_iops')\n",
    "add_parent_level(disk_trans_uncached, 'Uncached Disk Operations (IOPS)')\n",
    "\n",
    "all_joins = [cpu_data, mem_data, disk_tput_cached, disk_trans_cached, disk_tput_uncached, disk_trans_uncached]\n",
    "if local_analysis:\n",
    "    all_joins.insert(0, local_data)\n",
    "if advisor_analysis:\n",
    "    all_joins.append(advisor_data)\n",
    "full_data = res_data.join(all_joins)\n",
    "full_data.sort_index(inplace=True)\n",
    "full_data.to_excel('final_out_test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AzMeta Resize Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "print(\"Report Date:\", datetime.datetime.now().isoformat())\n",
    "print(\"Total Annual Savings:\", \"${:,.2f}\".format(local_data[('AzMeta', 'annual_savings')].sum()), \"(Non-RI Pricing, SQL and Windows AHUB Licensing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present the dataset\n",
    "import matplotlib as plt\n",
    "import itertools\n",
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "def background_limit_coloring(row):\n",
    "    cmap=\"coolwarm\"\n",
    "    text_color_threshold=0.408\n",
    "    limit_index = (row.index.get_level_values(0)[0], 'new_limit')\n",
    "    smin = 0\n",
    "    smax = row[limit_index] \n",
    "    if pd.isna(smax):\n",
    "        return [''] * len(row)\n",
    "    \n",
    "    rng = smax - smin\n",
    "    norm = colors.Normalize(smin, smax)\n",
    "    rgbas = plt.cm.get_cmap(cmap)(norm(row.to_numpy(dtype=float)))\n",
    "\n",
    "    def relative_luminance(rgba):\n",
    "        r, g, b = (\n",
    "            x / 12.92 if x <= 0.03928 else ((x + 0.055) / 1.055 ** 2.4)\n",
    "            for x in rgba[:3]\n",
    "        )\n",
    "        return 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "\n",
    "    def css(rgba):\n",
    "        dark = relative_luminance(rgba) < text_color_threshold\n",
    "        text_color = \"#f1f1f1\" if dark else \"#000000\"\n",
    "        return f\"background-color: {colors.rgb2hex(rgba)};color: {text_color};\"\n",
    "    \n",
    "    return [css(rgba) for rgba in rgbas[0:-1]] + ['']\n",
    "\n",
    "\n",
    "def build_header_style(col_groups):\n",
    "    start = 0\n",
    "    styles = []\n",
    "    palette = ['#f6f6f6', '#eae9e9', '#d4d7dd', '#f6f6f6', '#eae9e9', '#d4d7dd', '#f6f6f6', '#eae9e9', '#d4d7dd']\n",
    "    for i,group in enumerate(itertools.groupby(col_groups, lambda c:c[0])):\n",
    "        styles.append({'selector': f'.col_heading.level0.col{start}', 'props': [('background-color', palette[i])]})\n",
    "        group_len = len(tuple(group[1]))\n",
    "        for j in range(group_len):\n",
    "            styles.append({'selector': f'.col_heading.level1.col{start + j}', 'props': [('background-color', palette[i])]})\n",
    "        start += group_len\n",
    "    return styles\n",
    "\n",
    "\n",
    "data_group_names = [x for x in full_data.columns.get_level_values(0).unique() if x not in ('Resource', 'AzMeta', 'Advisor')]\n",
    "num_mask = [x[0] in data_group_names for x in full_data.columns.to_flat_index()]\n",
    "styler = full_data.style.hide_index() \\\n",
    "    .set_properties(**{'font-weight': 'bold'}, subset=[('Resource', 'resource_name')]) \\\n",
    "    .format('{:.1f}', subset=num_mask, na_rep='N/A') \\\n",
    "    .format('${:.2f}', subset=[('AzMeta', 'annual_savings')], na_rep='N/A') \\\n",
    "    .set_table_styles(build_header_style(full_data.columns))\n",
    "for data_group in data_group_names:\n",
    "    mask = [x == data_group for x in full_data.columns.get_level_values(0)]\n",
    "    styler = styler.apply(background_limit_coloring, axis=1, subset=mask)\n",
    "styler"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}